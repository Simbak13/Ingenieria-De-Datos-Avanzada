{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0Mg4ELwqbulrPpH4lsEhk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simbak13/Ingenieria-De-Datos-Avanzada/blob/main/01_PySpark_Con_MongoDB_Atlas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Agrega la base de datos de ejemplo sample_suplies en Atlas. Revisa para ello el Documento Word que se Adjunta. (Esto fue configurado en Mongo Atlas).**"
      ],
      "metadata": {
        "id": "1gvZmHTBINky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalacion de PySpark**"
      ],
      "metadata": {
        "id": "3C_DeAHnJALF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzg-Q6d48Rt4",
        "outputId": "eb19b7df-86de-49e0-aa34-52d9da7078a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Descarga e instala PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verificar que se instalo PySpark**"
      ],
      "metadata": {
        "id": "4tQimP9VJKRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la versión e imprimir\n",
        "print(\"\\nVersión de PySpark:\")\n",
        "!pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2E_37wC8huX",
        "outputId": "c20733ac-d7e0-4997-ec61-4ecf1b576dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Versión de PySpark:\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.28\n",
            "Branch HEAD\n",
            "Compiled by user heartsavior on 2024-02-15T11:24:58Z\n",
            "Revision fd86f85e181fc2dc0f50a096855acf83a6cc5d9c\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Crea un notebook en Colab y construye la conexión de SparkSession con MongoDB usando la cadena SRV. Usa el nombre de usuario y password que creaste en el paso**"
      ],
      "metadata": {
        "id": "LTt3QgGDJd1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Configura tu cadena de conexión aquí\n",
        "usuario = \"user_256057\"\n",
        "password = \"256057\"\n",
        "cluster = \"cluster0.fahly7d.mongodb.net\"  # por ejemplo: cluster0.abcd.mongodb.net\n",
        "basedatos = \"sample_supplies\"\n",
        "coleccion = \"clientes\"\n",
        "\n",
        "uri = f\"mongodb+srv://{usuario}:{password}@{cluster}/{basedatos}\"\n",
        "\n",
        "# Crear la sesión Spark con el conector de MongoDB\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MongoDB_Atlas_Connection\") \\\n",
        "    .config(\"spark.mongodb.read.connection.uri\", uri) \\\n",
        "    .config(\"spark.mongodb.write.connection.uri\", uri) \\\n",
        "    .config(\"spark.jars.packages\",\n",
        "            \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Conexión SparkSession creada con éxito\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTsL3P6I9kRk",
        "outputId": "821bbfc6-c021-4e6d-89ac-d96f015ffda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conexión SparkSession creada con éxito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Muestra que la conexión ha sido existosa.**"
      ],
      "metadata": {
        "id": "kjRyMgG5J7k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = spark.read.format(\"mongo\").option(\"uri\", f\"{uri}.{coleccion}\").load()\n",
        "    print(\"Conexión a MongoDB Atlas exitosa. Muestra de datos:\")\n",
        "    df.show(5)\n",
        "except Exception as e:\n",
        "    print(\"Error en la conexión o lectura de datos:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMaC8Snf-mSu",
        "outputId": "f5bd5c57-308d-405a-b468-9878ddcf47ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conexión a MongoDB Atlas exitosa. Muestra de datos:\n",
            "++\n",
            "||\n",
            "++\n",
            "++\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Usa la base de datos sample_supplies y lee la colección \"sales\" como un dataframe y explórala. Imprime el schema, número de filas estimadas (count) y el tipo de datos (df.dtypes).**"
      ],
      "metadata": {
        "id": "H8Y_n9rXKdfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Leer la colección sales como DataFrame**"
      ],
      "metadata": {
        "id": "aEV8ZNxO_Pb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer la colección sales\n",
        "df = spark.read.format(\"mongo\").option(\"uri\", f\"{uri}.sales\").load()\n",
        "\n",
        "print(\"Lectura de la colección 'sales' completada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRxKBx5L_RzI",
        "outputId": "9ee19c3d-bdf1-4924-d52c-9d7ad50a49bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lectura de la colección 'sales' completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imprimir el esquema**\n",
        "\n"
      ],
      "metadata": {
        "id": "aaAWsEdH_jrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Esquema del DataFrame:\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZtd9yyX_nGe",
        "outputId": "a9798d6c-36d4-4655-b9ab-354ac93f705b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esquema del DataFrame:\n",
            "root\n",
            " |-- _id: struct (nullable = true)\n",
            " |    |-- oid: string (nullable = true)\n",
            " |-- couponUsed: boolean (nullable = true)\n",
            " |-- customer: struct (nullable = true)\n",
            " |    |-- gender: string (nullable = true)\n",
            " |    |-- age: integer (nullable = true)\n",
            " |    |-- email: string (nullable = true)\n",
            " |    |-- satisfaction: integer (nullable = true)\n",
            " |-- items: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |    |    |-- price: decimal(6,2) (nullable = true)\n",
            " |    |    |-- quantity: integer (nullable = true)\n",
            " |    |    |-- tags: array (nullable = true)\n",
            " |    |    |    |-- element: string (containsNull = true)\n",
            " |-- purchaseMethod: string (nullable = true)\n",
            " |-- saleDate: timestamp (nullable = true)\n",
            " |-- storeLocation: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contar número de filas**"
      ],
      "metadata": {
        "id": "u7w0ZKqg_t4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de filas en 'sales': {df.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHwH7UhmLcQQ",
        "outputId": "7ee70eee-9c27-4ad8-e33e-564b05ac9f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de filas en 'sales': 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mostrar los tipos de datos de cada columna**"
      ],
      "metadata": {
        "id": "GsbzqVeQAEom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tipos de datos:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VprsacY0AKSW",
        "outputId": "50fc965a-00ce-403e-84cb-968f7cb564d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipos de datos:\n",
            "[('_id', 'struct<oid:string>'), ('couponUsed', 'boolean'), ('customer', 'struct<gender:string,age:int,email:string,satisfaction:int>'), ('items', 'array<struct<name:string,price:decimal(6,2),quantity:int,tags:array<string>>>'), ('purchaseMethod', 'string'), ('saleDate', 'timestamp'), ('storeLocation', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Crea una vista temporal llamada \"sales_view\" y ejecuta las siguientes consultas en Spark SQL**"
      ],
      "metadata": {
        "id": "K48Fwn2lMH4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la vista temporal\n",
        "df.createOrReplaceTempView(\"sales_view\")\n",
        "\n",
        "print(\"Vista temporal 'sales_view' creada correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTNGOLkQBI8C",
        "outputId": "8f0ecf89-e842-4d7c-c4a7-62412c9ae8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vista temporal 'sales_view' creada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**A partir de aquí, genera las consultas tanto en SQL y en expresiones Lambda. ⭐**"
      ],
      "metadata": {
        "id": "FgUAO94pM_Hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**a) Consulta cuántos documentos tiene sales_view.**"
      ],
      "metadata": {
        "id": "vnJ24-q1NWst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL ✅**"
      ],
      "metadata": {
        "id": "VUPzrrknNxSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar número de documentos (filas) en la vista temporal\n",
        "resultado = spark.sql(\"SELECT COUNT(*) AS total_documentos FROM sales_view\")\n",
        "\n",
        "# Mostrar el resultado\n",
        "resultado.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSYHyGmBers",
        "outputId": "c3fbbe8e-0e45-41bb-8038-f2e207a5c063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|total_documentos|\n",
            "+----------------+\n",
            "|            5000|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expresiones Lambda ✅**"
      ],
      "metadata": {
        "id": "2tDVxt7aN_oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_docs = df.count()\n",
        "print(f\"Total de documentos (sin SQL, método count()): {total_docs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kum9nnaRBw0S",
        "outputId": "5db95ab6-a45b-4846-fc80-7d15c509f0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de documentos (sin SQL, método count()): 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**b) Agrupa por storeLocation y ordena de mayor a menor.**"
      ],
      "metadata": {
        "id": "BFrMkJJ2OUtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL ✅**"
      ],
      "metadata": {
        "id": "HhtISi_OOY9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por storeLocation y ordenar de mayor a menor\n",
        "resultado_sql = spark.sql(\"\"\"\n",
        "    SELECT storeLocation, COUNT(*) AS total_ventas\n",
        "    FROM sales_view\n",
        "    GROUP BY storeLocation\n",
        "    ORDER BY total_ventas DESC\n",
        "\"\"\")\n",
        "\n",
        "# Mostrar resultados\n",
        "resultado_sql.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLcHZCnJCIIm",
        "outputId": "73b4745b-cf31-43e0-a651-4ae09f4701ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------+\n",
            "|storeLocation|total_ventas|\n",
            "+-------------+------------+\n",
            "|       Denver|        1549|\n",
            "|      Seattle|        1134|\n",
            "|       London|         794|\n",
            "|       Austin|         676|\n",
            "|     New York|         501|\n",
            "|    San Diego|         346|\n",
            "+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expresiones Lambda ✅**"
      ],
      "metadata": {
        "id": "rR22H4YjObko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Agrupar y ordenar sin SQL\n",
        "resultado_lambda = (\n",
        "    df.groupBy(\"storeLocation\")\n",
        "      .count()\n",
        "      .orderBy(F.desc(\"count\"))\n",
        ")\n",
        "\n",
        "resultado_lambda.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_ez6VgZPDmD",
        "outputId": "d7e84eb9-b0c5-4d55-812d-a13f149472c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|storeLocation|count|\n",
            "+-------------+-----+\n",
            "|       Denver| 1549|\n",
            "|      Seattle| 1134|\n",
            "|       London|  794|\n",
            "|       Austin|  676|\n",
            "|     New York|  501|\n",
            "|    San Diego|  346|\n",
            "+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**c) Imprime los clientes cuya edad es mayor 42**"
      ],
      "metadata": {
        "id": "RK-q-CQ-PRh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL ✅**"
      ],
      "metadata": {
        "id": "or-EkPMSPWAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clientes con edad mayor a 42 usando SQL\n",
        "resultado_sql = spark.sql(\"\"\"\n",
        "    SELECT customer.age AS edad, customer.email AS email, storeLocation\n",
        "    FROM sales_view\n",
        "    WHERE customer.age > 42\n",
        "\"\"\")\n",
        "\n",
        "resultado_sql.show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6A_B7wHC4Zu",
        "outputId": "56e89eef-32ca-44c2-bd39-059c38bd09fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------------+-------------+\n",
            "|edad|email            |storeLocation|\n",
            "+----+-----------------+-------------+\n",
            "|50  |keecade@hem.uy   |Seattle      |\n",
            "|51  |worbiduh@vowbu.cg|Denver       |\n",
            "|45  |vatires@ta.pe    |Seattle      |\n",
            "|44  |owtar@pu.cd      |London       |\n",
            "|71  |man@bob.mz       |Austin       |\n",
            "|57  |ohaguwu@nufub.gi |Denver       |\n",
            "|49  |merto@betosiv.pm |London       |\n",
            "|59  |la@cevam.tj      |San Diego    |\n",
            "|55  |eja@ko.es        |Seattle      |\n",
            "|53  |se@nacwev.an     |New York     |\n",
            "+----+-----------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expresiones Lambda ✅**"
      ],
      "metadata": {
        "id": "tIs812ptPYif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrar clientes con edad > 42\n",
        "resultado_lambda = (\n",
        "    df.filter(F.col(\"customer.age\") > 42)\n",
        "      .select(\"customer.age\", \"customer.email\", \"storeLocation\")\n",
        ")\n",
        "\n",
        "resultado_lambda.show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLcTs5oJDZBb",
        "outputId": "85874a43-b162-4368-e1d4-ff26a0529c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------+-------------+\n",
            "|age|email            |storeLocation|\n",
            "+---+-----------------+-------------+\n",
            "|50 |keecade@hem.uy   |Seattle      |\n",
            "|51 |worbiduh@vowbu.cg|Denver       |\n",
            "|45 |vatires@ta.pe    |Seattle      |\n",
            "|44 |owtar@pu.cd      |London       |\n",
            "|71 |man@bob.mz       |Austin       |\n",
            "|57 |ohaguwu@nufub.gi |Denver       |\n",
            "|49 |merto@betosiv.pm |London       |\n",
            "|59 |la@cevam.tj      |San Diego    |\n",
            "|55 |eja@ko.es        |Seattle      |\n",
            "|53 |se@nacwev.an     |New York     |\n",
            "+---+-----------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**d) Imprime el valor mínimo y máximo de satisfaction que está dentro de customer.**"
      ],
      "metadata": {
        "id": "-1fYzEgfQOzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL ✅**"
      ],
      "metadata": {
        "id": "IX1fkT5FQUnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta SQL para obtener el valor mínimo y máximo de satisfacción\n",
        "resultado_sql = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        MIN(customer.satisfaction) AS min_satisfaction,\n",
        "        MAX(customer.satisfaction) AS max_satisfaction\n",
        "    FROM sales_view\n",
        "\"\"\")\n",
        "\n",
        "resultado_sql.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYAFUoR3QdxT",
        "outputId": "d1286b13-a987-4d51-a560-42105f5975ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+\n",
            "|min_satisfaction|max_satisfaction|\n",
            "+----------------+----------------+\n",
            "|               1|               5|\n",
            "+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expresiones Lambda ✅**"
      ],
      "metadata": {
        "id": "cABmOu0sQWu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular valores mínimo y máximo de satisfacción\n",
        "resultado_lambda = df.agg(\n",
        "    F.min(\"customer.satisfaction\").alias(\"min_satisfaction\"),\n",
        "    F.max(\"customer.satisfaction\").alias(\"max_satisfaction\")\n",
        ")\n",
        "\n",
        "resultado_lambda.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKBbGa-0QpdT",
        "outputId": "c596f2ed-d01f-4af1-a839-e7277cbcd39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+\n",
            "|min_satisfaction|max_satisfaction|\n",
            "+----------------+----------------+\n",
            "|               1|               5|\n",
            "+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**e) Agrupa por el mètodo de compra purchaseMethod y ordena.**"
      ],
      "metadata": {
        "id": "yjQvui8qQ0C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SQL ✅**"
      ],
      "metadata": {
        "id": "kVRKLoEpQ7Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por método de compra y ordenar de mayor a menor\n",
        "resultado_sql = spark.sql(\"\"\"\n",
        "    SELECT purchaseMethod, COUNT(*) AS total_compras\n",
        "    FROM sales_view\n",
        "    GROUP BY purchaseMethod\n",
        "    ORDER BY total_compras DESC\n",
        "\"\"\")\n",
        "\n",
        "resultado_sql.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPjSsgWyHF9R",
        "outputId": "2bb80111-42f2-44fa-c289-9f0bada8b817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+\n",
            "|purchaseMethod|total_compras|\n",
            "+--------------+-------------+\n",
            "|      In store|         2819|\n",
            "|        Online|         1585|\n",
            "|         Phone|          596|\n",
            "+--------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expresiones Lambda ✅**"
      ],
      "metadata": {
        "id": "OqwkvtI_Q8tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Agrupar y ordenar con la API de DataFrame (lambda-style)\n",
        "resultado_lambda = (\n",
        "    df.groupBy(\"purchaseMethod\")\n",
        "      .count()\n",
        "      .orderBy(F.desc(\"count\"))\n",
        ")\n",
        "\n",
        "resultado_lambda.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhuJ4A6BRLXA",
        "outputId": "7bc2b7e6-326e-4d98-f1ec-330dc4e2afbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|purchaseMethod|count|\n",
            "+--------------+-----+\n",
            "|      In store| 2819|\n",
            "|        Online| 1585|\n",
            "|         Phone|  596|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}